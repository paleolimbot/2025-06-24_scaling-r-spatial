---
title: "Scaling the r-spatial ecosystem"
subtitle: "...for the modern composable data pipeline"
author: "Dewey Dunnington (@paleolimbot)"
institute: ""
format:
  revealjs:
    embed-resources: true
    title-slide-attributes:
      data-background-image: bg/wb0.png
      data-background-color: "#2556BB"
---

```{r setup, include = FALSE}
library(tidyverse)
library(sf)
```

## Me {background-image="bg/wb4.png"}

::: {style="text-align: center;"}

![](logo/arrow-hex.png){width="20%"} ![](logo/nanoarrow-hex.png){width="20%"} ![](logo/geoarrow_logo.png){width="20%"} ![](logo/sf.gif){width="20%"}

:::

::: {style="text-align: center;"}

![](logo/sedona_logo.png){width="70%"}

:::

::: {style="text-align: center;"}

![](logo/wherobots.png){width="50%"}

:::

## Me in #rstats {background-image="bg/wb3.png"}

Maintainer of s2, wk, geos, geoarrow, nanoarrow, tidypaleo, ggspatial, adbc(drivermanager|sqlite|postgresql)

Contributor to qgisprocess, arrow, ggplot2

## Places to find/ask/share {background-image="bg/wb3.png"}

I'm now a low-level nuts-and-bolts developer a few years removed from day-to-day usage. If you have questions, feedback, or expertise to share there are some great venues!

- [geocomp*x*](https://geocompx.org/) (on Discord and elsewhere)
- [paleolimbot/2025-06-24_scaling-r-spatial](https://github.com/paleolimbot/2025-06-24_scaling-r-spatial)
- `@paleolimbot` on Discord/BlueSky/Fosstodon/GitHub

## {background="#2556BB"}

<br/>

<br/>

::: {style="text-align: center;"}

### sf for big(ger) data

<br/>

### Beyond sf (s2, geos, wk, and more)

<br/>

### Driving spatial databases from R

:::

## sf for big(ger) data: filter-on-read

Say you have a data source and an area you're interested in:

```{r}
bounds_lonlat <- st_bbox(
  c(xmin = -64.6418, xmax = -64.2868, ymin = 44.8473, ymax = 45.0151),
  crs = st_crs("OGC:CRS84")
)
```

## sf for big(ger) data: filter-on-read

```{r}
#| echo: true
#| eval: false
system.time({
  # Read the file
  elevation <- read_sf("data/ns-water_elevation.fgb")

  # Transform the bounds to the CRS of the source
  bounds_poly <- bounds_lonlat |>
    st_transform(st_crs(elevation)) |>
    st_as_sfc()

  # Filter to area of interest
  elevation <- elevation |>
    filter(st_intersects(elevation, bounds_poly[[1]], sparse = FALSE))
})
#>    user  system elapsed
#>  67.656   5.454  74.056
```

## sf for big(ger) data: filter-on-read

```{r}
#| echo: true
system.time({
  # Read the CRS of the source
  elevation_crs <- st_layers("data/ns-water_elevation.fgb")$crs[[1]]

  # Transform the bounds to the CRS of the source
  bounds_poly <- bounds_lonlat |>
    st_transform(elevation_crs) |>
    st_as_sfc()

  # Read just the data you need
  elevation <- st_read(
    "data/ns-water_elevation.fgb",
    wkt_filter = st_as_text(bounds_poly)
  )
})
#>    user  system elapsed
#>   7.146   0.478   7.641
```

## sf for big(ger) data: `st_join()`

Let's look at the interaction of the elevation points with some lakes.

```{r}
lakes <- read_sf("data/ns-water_water-poly.fgb")
lakes <- lakes |>
  filter(st_intersects(lakes, bounds_poly[[1]], sparse = FALSE)) |>
  st_transform(st_crs(elevation))
```

## sf for big(ger) data: `st_join()`

If we wanted to find the mean elevation of each lake, we might do something like this:

```{r}
#| echo: true
#| eval: false
system.time({
  lakes$mean_elev <- lakes$geometry |>
    map_dbl(~{
      elev_is_relevant <- st_intersects(elevation, .x, sparse = FALSE)
      mean(elevation$ZVALUE[elev_is_relevant])
    })
})
#>    user  system elapsed
#> 220.054   3.715 223.819
```

## sf for big(ger) data: `st_join()`

What we want here is a join!

```{r}
system.time({
  lakes |>
    mutate(row_id = row_number()) |>
    st_join(elevation, join = st_intersects) |>
    group_by(row_id) |>
    summarise(mean_elev = mean(ZVALUE.y))
})
#>    user  system elapsed
#>  10.418   0.582  11.004
```

## Data types: Geography {background-image="bg/wb3.png"}

:::: {.columns}

::: {.column width="50%"}

Spherely array:

- Order is kept
- In memory data structures
- Requires explicit parallelization

:::

::: {.column width="50%"}

DuckDB Geography:

- Order is sometimes kept
- Serialized data structures (can be slower)
- Automatic parallelization

:::

::::

## {background="#2556BB"}

<br/>

<br/>

::: {style="text-align: center;"}

### Using sf for bigger data

<br/>

### Partitioning

<br/>

### Joining

:::

## The Future

- Better integration with `spatial` (e.g., `geog::GEOMETRY`)
- Aggregators
- Import/Export/Fix spherical geometry
- Something else based on user experience?

## Scaling r-spatial {background-image="bg/wb3.png"}

- [dewey.dunnington.ca/slides/rspatial2025](https://dewey.dunnington.ca/slides/rspatial2025)
- {{< fa brands github >}} [paleolimbot/duckdb-geography](https://github.com/paleolimbot/2025-06-24_scaling-r-spatial)

## Getting the data {background-image="bg/wb3.png"}

```{r}
#| echo: true
#| eval: false
curl::curl_download(
  "https://github.com/geoarrow/geoarrow-data/releases/download/v0.2.0/ns-water_elevation.fgb",
  "data/ns-water_elevation.fgb"
)

curl::curl_download(
  "https://github.com/geoarrow/geoarrow-data/releases/download/v0.2.0/ns-water_water-poly.fgb",
  "data/ns-water_water-poly.fgb"
)
```

